# ============================================================================
# LLM API KEYS
# ============================================================================

# Groq API Configuration (Required for Llama 3.3 70B)
GROQ_API_KEY=your_groq_api_key_here

# AWS Bedrock Configuration (Required for Claude)
AWS_ACCESS_KEY_ID=your_aws_access_key_here
AWS_SECRET_ACCESS_KEY=your_aws_secret_key_here
AWS_SESSION_TOKEN=your_aws_session_token_here  # Optional, only if using temporary credentials
AWS_REGION=us-east-1

# Google Generative AI Configuration (Required for Gemini)
GOOGLE_API_KEY=your_google_api_key_here

# ============================================================================
# MODEL CONFIGURATION
# ============================================================================

# Groq Model
MODEL_NAME=llama-3.3-70b-versatile
TEMPERATURE=0.1

# Claude ARN Model ID (AWS Bedrock)
CLAUDE_MODEL_ID=anthropic.claude-3-5-sonnet-20241022-v2:0

# Gemini Model
GEMINI_MODEL_ID=gemini-2.0-flash-exp

# Model Selection
AVAILABLE_MODELS=groq,claude,gemini  # Comma-separated list of available models
DEFAULT_MODEL=groq  # Default model to use in pipeline

# ============================================================================
# FEATURE EXTRACTION THRESHOLDS
# ============================================================================

BLUR_THRESHOLD=100.0
BACKGROUND_CLEANLINESS_THRESHOLD=0.6
MIN_OBJECT_CONFIDENCE=0.5

# ============================================================================
# LOGGING
# ============================================================================

LOG_LEVEL=INFO